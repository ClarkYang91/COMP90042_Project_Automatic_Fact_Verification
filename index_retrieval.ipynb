{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5d6f9d3846df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'docname'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'contents'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m \u001b[0msearch_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSearchEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./wiki-pages-text'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'./IndexFiles.index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misindexing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[0mserach_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./wiki-pages-text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-5d6f9d3846df>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, storedir, isindexing, isBM25)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndexWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mticker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTicker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'commit index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================== Indexer imports ========================\n",
    "import sys, os, threading, time\n",
    "from java.nio.file import Paths\n",
    "from org.apache.lucene.analysis.miscellaneous import LimitTokenCountAnalyzer\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.document import Document, Field, FieldType\n",
    "from org.apache.lucene.index import \\\n",
    "    FieldInfo, IndexWriter, IndexWriterConfig, IndexOptions\n",
    "from org.apache.lucene.store import SimpleFSDirectory\n",
    "\n",
    "# ======================= Retriever imports =======================\n",
    "from org.apache.lucene.index import DirectoryReader\n",
    "from org.apache.pylucene.queryparser.classic import PythonMultiFieldQueryParser\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search import IndexSearcher, BooleanClause\n",
    "from org.apache.lucene.search.similarities import BM25Similarity\n",
    "\n",
    "\n",
    "class Ticker(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tick = True\n",
    "\n",
    "    def run(self):\n",
    "        while self.tick:\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(1.0)\n",
    "\n",
    "\n",
    "class SearchEngine(object):\n",
    "    \n",
    "    lucene.initVM(classpath=lucene.CLASSPATH, maxheap=\"512m\")\n",
    "    lucene.getVMEnv().attachCurrentThread()\n",
    "\n",
    "\n",
    "    def __init__(self, root, storedir, isindexing=False, isBM25=True):\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        if not os.path.exists(storedir):\n",
    "            os.mkdir(storedir)\n",
    "\n",
    "        self.analyzer = LimitTokenCountAnalyzer(StandardAnalyzer(), 1048576)\n",
    "\n",
    "        if isindexing:\n",
    "            store = SimpleFSDirectory(Paths.get(storedir))\n",
    "            config = IndexWriterConfig(self.analyzer)\n",
    "            # TODO BM25 parameter tuning\n",
    "            if isBM25:\n",
    "                config.setSimilarity(BM25Similarity())\n",
    "            config.setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n",
    "            self.writer = IndexWriter(store, config)\n",
    "\n",
    "            self.indexer(root, writer)\n",
    "            ticker = Ticker()\n",
    "            print('commit index')\n",
    "            threading.Thread(target=ticker.run).start()\n",
    "            writer.commit()\n",
    "            writer.close()\n",
    "            ticker.tick = False\n",
    "            print('done')\n",
    "\n",
    "        search_dir = SimpleFSDirectory(Paths.get(storedir))\n",
    "        self.searcher = IndexSearcher(DirectoryReader.open(search_dir))\n",
    "        if isBM25:\n",
    "            self.searcher.setSimilarity(BM25Similarity())\n",
    "\n",
    "    def indexer(self, root):\n",
    "\n",
    "        t1 = FieldType()\n",
    "        t1.setStored(True)\n",
    "        t1.setTokenized(True)\n",
    "        t1.setIndexOptions(IndexOptions.DOCS_AND_FREQS)\n",
    "\n",
    "        def repalcer(text):\n",
    "            chars = '\\\\`*_{}[]()>#+-.!$â€˜'\n",
    "            for c in chars:\n",
    "                if c in text:\n",
    "                    text = text.replace(c, ' ')\n",
    "            return text\n",
    "\n",
    "        for root, dirnames, filenames in os.walk(root):\n",
    "            i = 0\n",
    "            for filename in filenames:\n",
    "                i += 1\n",
    "                with open(os.path.join(root, filename)) as f:\n",
    "                    for line in f.readlines():\n",
    "                        line = line.split(' ', 2)\n",
    "                        docname = line[0] + ' ' + line[1]\n",
    "                        name = repalcer(line[0])\n",
    "                        contents = line[2]\n",
    "                        doc = Document()\n",
    "                        doc.add(Field('docname', docname, t1))\n",
    "                        doc.add(Field('name', name, t1))\n",
    "                        doc.add(Field('contents', contents, t1))\n",
    "                        self.writer.addDocument(doc)\n",
    "                print('File %d done indexing' % i)\n",
    "\n",
    "    def search(self, query, topk=10):\n",
    "\n",
    "        qp = PythonMultiFieldQueryParser(['name', 'contents'], self.analyzer)\n",
    "        query = qp.parse(query, ['name', 'contents'],\n",
    "                         [BooleanClause.Occur.SHOULD, BooleanClause.Occur.SHOULD], self.analyzer)\n",
    "        # print(query)\n",
    "        scores = self.searcher.search(query, topk).scoreDocs\n",
    "        # print('%s total matching documents.' % len(scores))\n",
    "\n",
    "        docnames = []\n",
    "        doccontents = []\n",
    "        for score in scores:\n",
    "            doc = self.searcher.doc(score.doc)\n",
    "            docnames.append(doc.get('docname'))\n",
    "            doccontents.append(doc.get('contents'))\n",
    "\n",
    "        return docnames, doccontents\n",
    "\n",
    "    def retrieve(self, term, sid):\n",
    "\n",
    "        query = term + ' ' + str(sid)\n",
    "        query = QueryParser.escape(query)\n",
    "        query = QueryParser('docname', self.analyzer).parse(query)\n",
    "        score = self.searcher.search(query, 1).scoreDocs\n",
    "\n",
    "        doc = self.searcher.doc(score[0].doc)\n",
    "        return doc.get('docname'), doc.get('contents')\n",
    "\n",
    "search_engine = SearchEngine('./wiki-pages-text','./IndexFiles.index', isindexing=True)\n",
    "serach_engine.indexer('./wiki-pages-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucene"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
